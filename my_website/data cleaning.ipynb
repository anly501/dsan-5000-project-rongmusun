{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Data Cleaning\"\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will check the raw data and clean the data that we gathered for our analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to check null values for each datasets. As we can see, the data we gain from this API do not have any Null values, then we need to calculate daily return for each row, to make the dataset not time-sensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp    0\n",
      "open         0\n",
      "high         0\n",
      "low          0\n",
      "close        0\n",
      "volume       0\n",
      "dtype: int64\n",
      "timestamp     object\n",
      "open         float64\n",
      "high         float64\n",
      "low          float64\n",
      "close        float64\n",
      "volume         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#For AAPL dataset\n",
    "AAPL = pd.read_csv('AAPL_six_months_data.csv')\n",
    "\n",
    "#Check for missing values\n",
    "missing_values = AAPL.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "#Check data type\n",
    "print(AAPL.dtypes)\n",
    "\n",
    "#Calculate daily return\n",
    "AAPL['daily_return'] = AAPL['close'].pct_change() * 100\n",
    "AAPL.head()\n",
    "\n",
    "AAPL.to_csv('AAPL_Cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp    0\n",
      "open         0\n",
      "high         0\n",
      "low          0\n",
      "close        0\n",
      "volume       0\n",
      "dtype: int64\n",
      "timestamp     object\n",
      "open         float64\n",
      "high         float64\n",
      "low          float64\n",
      "close        float64\n",
      "volume         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#For MSFT dataset\n",
    "MSFT = pd.read_csv('MSFT_six_months_data.csv')\n",
    "\n",
    "#Check for missing values\n",
    "missing_values = MSFT.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "#Check data type\n",
    "print(MSFT.dtypes)\n",
    "\n",
    "#Calculate daily return\n",
    "MSFT['daily_return'] = MSFT['close'].pct_change() * 100\n",
    "MSFT.head()\n",
    "\n",
    "MSFT.to_csv('MSFT_Cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp    0\n",
      "open         0\n",
      "high         0\n",
      "low          0\n",
      "close        0\n",
      "volume       0\n",
      "dtype: int64\n",
      "timestamp     object\n",
      "open         float64\n",
      "high         float64\n",
      "low          float64\n",
      "close        float64\n",
      "volume         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#For GOOGL dataset\n",
    "GOOGL = pd.read_csv('GOOGL_six_months_data.csv')\n",
    "\n",
    "#Check for missing values\n",
    "missing_values = GOOGL.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "#Check data type\n",
    "print(GOOGL.dtypes)\n",
    "\n",
    "#Calculate daily return\n",
    "GOOGL['daily_return'] = GOOGL['close'].pct_change() * 100\n",
    "GOOGL.head()\n",
    "\n",
    "GOOGL.to_csv('GOOGL_Cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp    0\n",
      "open         0\n",
      "high         0\n",
      "low          0\n",
      "close        0\n",
      "volume       0\n",
      "dtype: int64\n",
      "timestamp     object\n",
      "open         float64\n",
      "high         float64\n",
      "low          float64\n",
      "close        float64\n",
      "volume         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#For AMZN dataset\n",
    "AMZN = pd.read_csv('AMZN_six_months_data.csv')\n",
    "\n",
    "#Check for missing values\n",
    "missing_values = AMZN.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "#Check data type\n",
    "print(AMZN.dtypes)\n",
    "\n",
    "#Calculate daily return\n",
    "AMZN['daily_return'] = AMZN['close'].pct_change() * 100\n",
    "AMZN.head()\n",
    "\n",
    "AMZN.to_csv('AMZN_Cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp    0\n",
      "open         0\n",
      "high         0\n",
      "low          0\n",
      "close        0\n",
      "volume       0\n",
      "dtype: int64\n",
      "timestamp     object\n",
      "open         float64\n",
      "high         float64\n",
      "low          float64\n",
      "close        float64\n",
      "volume         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#For META dataset\n",
    "META = pd.read_csv('META_six_months_data.csv')\n",
    "\n",
    "#Check for missing values\n",
    "missing_values = META.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "#Check data type\n",
    "print(META.dtypes)\n",
    "\n",
    "#Calculate daily return\n",
    "META['daily_return'] = META['close'].pct_change() * 100\n",
    "META.head()\n",
    "\n",
    "META.to_csv('META_Cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp    0\n",
      "open         0\n",
      "high         0\n",
      "low          0\n",
      "close        0\n",
      "volume       0\n",
      "dtype: int64\n",
      "timestamp     object\n",
      "open         float64\n",
      "high         float64\n",
      "low          float64\n",
      "close        float64\n",
      "volume         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#For TSLA dataset\n",
    "TSLA = pd.read_csv('TSLA_six_months_data.csv')\n",
    "\n",
    "#Check for missing values\n",
    "missing_values = TSLA.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "#Check data type\n",
    "print(TSLA.dtypes)\n",
    "\n",
    "#Calculate daily return\n",
    "TSLA['daily_return'] = TSLA['close'].pct_change() * 100\n",
    "TSLA.head()\n",
    "\n",
    "TSLA.to_csv('TSLA_Cleaned.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
