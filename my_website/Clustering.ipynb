{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Dimensionality Reduction\"\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset AAPL includes the information about Apple's stock price for recent half years. In order to make it to be not time sensitive, I add a column called daily return which calculates the difference between open stock price and close stock price in each single day. This dataset also has a column which represents the trading volumn for each day. I am doing clustering for these two variables and to find out the most common situation for Apple's stock holders."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means: randomly initialize centroids and assign each data point to the nearest centroid, and then re-locate the centroids, and repeat the process of assigning data points and calculating new means for each centroid, until the centroids do not change significantly after recalculating.\n",
    "\n",
    "Elbow method: calculate the sum of squared distances of samples to centroids, make a plot and find out the elbow point, where the rate of increase/decrease slow down.\n",
    "\n",
    "Silhouette: The silhouette ranges from -1 to 1, higher score means better match for the closest centroid, the highest silhouette score represents the optimal choice."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBSCAN: Density-Based Spatial Clustering of Applications with Noise, it creates clusters based on the density of data points. When using this algorithm, we needs to determine the eps (the radius of a neighborhood around a point) and min_samples (the minimum number of points required to form a dense region). We start with a random point, form cluster for all points within the neighborhood, repeat the process until all points get labeled (core, border, noise)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierarchical: There are two forms in hierarchical clustering: agglomerative(bottom-up) and divisive(top-down). In agglomerative, we start by treating each point as a cluster, then merge down the closest pair of clusters, repeat the process until there is only one big cluster left. Divisive starts by a large cluster, and then break this cluster down."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
