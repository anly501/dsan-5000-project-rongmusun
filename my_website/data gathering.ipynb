{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Data Gathering\"\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Gathering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we gather the data that we will be using for this analysis. The data all comes from free API website Alphavantage."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, we will source our primary dataset from Alpha Vantage, focusing on the stock prices of six prominent high-tech companies -- \"AAPL, MSFT, GOOGL, AMZN, META, TSLA\", over the recent half-year period. These datasets serve as the base for our exploratory analysis, enabling us to look at the current market trends and behaviors specific to the technology sector."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the access of these datasets, we need to get our API key from AlphaVantage, then get the authentication of accessing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data stored for AAPL for the recent 6 months.\n",
      "Data stored for MSFT for the recent 6 months.\n",
      "Data stored for GOOGL for the recent 6 months.\n",
      "Data stored for AMZN for the recent 6 months.\n",
      "Data stored for META for the recent 6 months.\n",
      "Data stored for TSLA for the recent 6 months.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "api_key = 'PMPL4GDC4VRLN6XJ'\n",
    "\n",
    "def get_stock_data(symbol, api_key):\n",
    "    \n",
    "    url = f'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={symbol}&outputsize=full&apikey={api_key}&datatype=csv'\n",
    "    r = requests.get(url)\n",
    "    if r.status_code == 200:\n",
    "        \n",
    "        df = pd.read_csv(url)\n",
    "        \n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        \n",
    "        six_months_ago = datetime.now() - timedelta(days=6*30)  \n",
    "        filtered_df = df[df['timestamp'] >= six_months_ago]\n",
    "        return filtered_df\n",
    "    else:\n",
    "        print(f\"Error fetching data: {r.status_code}\")\n",
    "        return None\n",
    "\n",
    "stock_symbol = 'AAPL'\n",
    "data = get_stock_data(stock_symbol, api_key)\n",
    "\n",
    "if data is not None:\n",
    "    \n",
    "    data.to_csv(f'{stock_symbol}_six_months_data.csv', index=False)\n",
    "    print(f\"Data stored for {stock_symbol} for the recent 6 months.\")\n",
    "else:\n",
    "    print(\"No data to store.\")\n",
    "\n",
    "\n",
    "stock_symbol = 'MSFT'\n",
    "data = get_stock_data(stock_symbol, api_key)\n",
    "\n",
    "if data is not None:\n",
    "\n",
    "    data.to_csv(f'{stock_symbol}_six_months_data.csv', index=False)\n",
    "    print(f\"Data stored for {stock_symbol} for the recent 6 months.\")\n",
    "else:\n",
    "    print(\"No data to store.\")\n",
    "\n",
    "stock_symbol = 'GOOGL'\n",
    "data = get_stock_data(stock_symbol, api_key)\n",
    "\n",
    "\n",
    "if data is not None:\n",
    "\n",
    "    data.to_csv(f'{stock_symbol}_six_months_data.csv', index=False)\n",
    "    print(f\"Data stored for {stock_symbol} for the recent 6 months.\")\n",
    "else:\n",
    "    print(\"No data to store.\")\n",
    "\n",
    "stock_symbol = 'AMZN'\n",
    "data = get_stock_data(stock_symbol, api_key)\n",
    "\n",
    "\n",
    "if data is not None:\n",
    "\n",
    "    data.to_csv(f'{stock_symbol}_six_months_data.csv', index=False)\n",
    "    print(f\"Data stored for {stock_symbol} for the recent 6 months.\")\n",
    "else:\n",
    "    print(\"No data to store.\")\n",
    "\n",
    "stock_symbol = 'META'\n",
    "data = get_stock_data(stock_symbol, api_key)\n",
    "\n",
    "\n",
    "if data is not None:\n",
    "\n",
    "    data.to_csv(f'{stock_symbol}_six_months_data.csv', index=False)\n",
    "    print(f\"Data stored for {stock_symbol} for the recent 6 months.\")\n",
    "else:\n",
    "    print(\"No data to store.\")\n",
    "\n",
    "stock_symbol = 'TSLA'\n",
    "data = get_stock_data(stock_symbol, api_key)\n",
    "\n",
    "\n",
    "if data is not None:\n",
    "\n",
    "    data.to_csv(f'{stock_symbol}_six_months_data.csv', index=False)\n",
    "    print(f\"Data stored for {stock_symbol} for the recent 6 months.\")\n",
    "else:\n",
    "    print(\"No data to store.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also look at the real market trend in the United States, thus we also need the data for real gdp per capita to represent the current market trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'timestamp'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mif\u001b[39;00m r\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[1;32m      5\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(url)\n\u001b[0;32m----> 7\u001b[0m     df[\u001b[39m'\u001b[39m\u001b[39mtimestamp\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(df[\u001b[39m'\u001b[39;49m\u001b[39mtimestamp\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      9\u001b[0m     six_months_ago \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow() \u001b[39m-\u001b[39m timedelta(days\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m\u001b[39m*\u001b[39m\u001b[39m30\u001b[39m)  \n\u001b[1;32m     10\u001b[0m     filtered_df \u001b[39m=\u001b[39m df[df[\u001b[39m'\u001b[39m\u001b[39mtimestamp\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m six_months_ago]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'timestamp'"
     ]
    }
   ],
   "source": [
    "url = f'https://www.alphavantage.co/query?function=REAL_GDP_PER_CAPITA&outputsize=full&apikey={api_key}&datatype=csv'\n",
    "r = requests.get(url)\n",
    "if r.status_code == 200:\n",
    "        \n",
    "    df = pd.read_csv(url)\n",
    "    \n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        \n",
    "    six_months_ago = datetime.now() - timedelta(days=6*30)  \n",
    "    filtered_df = df[df['timestamp'] >= six_months_ago]\n",
    "else:\n",
    "    print(f\"Error fetching data: {r.status_code}\")\n",
    "\n",
    "if data is not None:\n",
    "\n",
    "    data.to_csv(f'Real_GDP_PER_CAPITA_six_months_data.csv', index=False)\n",
    "    print(f\"Data stored for the recent 6 months.\")\n",
    "else:\n",
    "    print(\"No data to store.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last dataset we need is the news for Apple, which we will use to find out the relationship between news or events to stock price in the future. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "api_key = 'PMPL4GDC4VRLN6XJ'\n",
    "ticker = 'AAPL'\n",
    "base_url = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers={ticker}&apikey={api_key}'\n",
    "\n",
    "all_data = []\n",
    "start_date = datetime(2023, 5, 1) \n",
    "\n",
    "for _ in range(20):  \n",
    "    time_from = start_date.strftime('%Y%m%dT%H%M')\n",
    "    url = f\"{base_url}&time_from={time_from}&limit=1000\"  # If limit=50 is the max allowed\n",
    "    r = requests.get(url)\n",
    "    data = r.json()\n",
    "    feed_data = data.get('feed', [])\n",
    "    \n",
    "    # Break the loop if no data is returned\n",
    "    if not feed_data:\n",
    "        break\n",
    "    \n",
    "    # Add the retrieved data to the all_data list\n",
    "    all_data.extend(feed_data)\n",
    "    \n",
    "    # Assuming the feed is ordered by time, update the start_date to the time of the last article\n",
    "    last_article_time = feed_data[-1]['time_published']\n",
    "    start_date = datetime.strptime(last_article_time, '%Y-%m-%dT%H:%M:%SZ') + timedelta(seconds=1)\n",
    "\n",
    "# Convert the collected data to a DataFrame\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"News_AAPL.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
