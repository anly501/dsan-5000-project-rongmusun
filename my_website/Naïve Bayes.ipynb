{
 "cells": [
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Naïve Bayes\"\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naïve Bayes\n",
    "## Introduction to Naive Bayes\n",
    "Naive Bayes is a probabilistic machine learning algorithm based on the Bayes' Theorem, used for classification tasks. it assumes that features in a dataset are mutually independent, which is a strong assumption. \n",
    "\n",
    "For each class and feature, the method calculates the mean and variance, which will be used to make probability estimates based on the Gaussian distribution. For each instance to be classified, we calculate the posterior probability for every class using the Bayes formula.\n",
    "Assume it is independence between features. So, for multiple features, the posterior probability is the product of individual probabilities of each feature. Then we compare the posterior probabilities across classes and assign the class with the highest probability to the instance, and the class with highest probability is our prediction\n",
    "\n",
    "There are three types of Naive Bayes Classifier: Gaussian, Multinomial, Bernoulli. They share common principles but differ in handling the type of data they are applied to.\n",
    "\n",
    "Gaussian Naive Bayes: Gaussian is best used in cases where features are continuous and can be assumed to have a Gaussian distribution. It assumes that features follow a normal distribution. Instead of using discrete counts, it uses the mean and variance of the features to estimate the probabilities. If the features are continuous, it assumes that these features are sampled from a Gaussian distribution (bell curve).\n",
    "\n",
    "Multinomial Naive Bayes: Multinomial is primarily used for document classification problems where the features are related to word counts or frequencies within the documents. This model is based on frequency counts. It calculates the likelihood of each outcome based on the frequency count of the features. The probabilities are then estimated for the new instance using these counts. It can handle the frequency of occurrences of outcomes in a dataset and is particularly useful for text classification.\n",
    "\n",
    "Bernoulli Naive Bayes: Bernoulli is suitable for datasets where features are binary or boolean, such as text classification where the presence or absence of a feature is more informative than frequency counts. It works similarly to the Multinomial Naive Bayes but with binary variables. It uses the Bernoulli distribution and assumes all our features are binary such that they take only two values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch news: 426\n",
      "                                              source  \\\n",
      "0                 {'id': None, 'name': 'Biztoc.com'}   \n",
      "1  {'id': None, 'name': 'Investor's Business Daily'}   \n",
      "2               {'id': None, 'name': 'Applech2.com'}   \n",
      "3               {'id': None, 'name': 'Applech2.com'}   \n",
      "4               {'id': None, 'name': 'Applech2.com'}   \n",
      "\n",
      "                      author  \\\n",
      "0              thestreet.com   \n",
      "1  Investor's Business Daily   \n",
      "2                   applech2   \n",
      "3                   applech2   \n",
      "4                   applech2   \n",
      "\n",
      "                                               title  \\\n",
      "0  One tech startup has found a solution to in-pe...   \n",
      "1  Dow Jones Futures: What To Do After Big Market...   \n",
      "2  AmazonでSatechiのMacBook Pro (14/16インチ)用ハードシェルケー...   \n",
      "3  macOS 14.1 SonomaではWindow Serverのバグにより、Adobe P...   \n",
      "4  エレコム、macOS 14 Sonomaでジェスチャー機能を割り当てした際、アプリが強制終了...   \n",
      "\n",
      "                                         description  \\\n",
      "0  As much as 2021 was synonymous with an enormou...   \n",
      "1  Warren Buffett's Berkshire reported strong ear...   \n",
      "2  AmazonでがSatechiのMacBook Pro (14/16インチ)用ハードシェルケ...   \n",
      "3  macOS 14.1 SonomaではWindow Serverのバグにより、Adobe P...   \n",
      "4  エレコムがmacOS 14 Sonomaでジェスチャー機能を割り当てした際、アプリが強制終了...   \n",
      "\n",
      "                                                 url           publishedAt  \\\n",
      "0              https://biztoc.com/x/9a75cf0635c15ca3  2023-11-05T13:10:15Z   \n",
      "1  https://www.investors.com/market-trend/stock-m...  2023-11-05T12:44:39Z   \n",
      "2  https://applech2.com/archives/20231105-satechi...  2023-11-05T09:13:08Z   \n",
      "3  https://applech2.com/archives/20231105-macos-1...  2023-11-05T08:43:57Z   \n",
      "4  https://applech2.com/archives/20231105-elecom-...  2023-11-05T07:02:58Z   \n",
      "\n",
      "                                             content  \n",
      "0  As much as 2021 was synonymous with an enormou...  \n",
      "1  Dow Jones futures will open Sunday evening, al...  \n",
      "2  AmazonSatechiMacBook Pro (14/16)iMac 24\\r\\nAma...  \n",
      "3  macOS 14.1 SonomaWindow ServerAdobe PhotoshopI...  \n",
      "4  macOS 14 Sonoma v5.2.12.002\\r\\n20231027 (Mac)v...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "api_key = '4ce9d5ba9ae046d8b647f0993345ef7f'\n",
    "\n",
    "url = 'https://newsapi.org/v2/everything'\n",
    "params = {\n",
    "    'q': 'Apple', \n",
    "    'from': '2023-05-08', \n",
    "    'to': '2023-11-01', \n",
    "    'sortBy': 'publishedAt', \n",
    "    'apiKey': api_key, \n",
    "}\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    articles = data['articles']\n",
    "    df_articles = pd.DataFrame(articles)\n",
    "    print(df_articles.head())\n",
    "else:\n",
    "    print(f\"Failed to fetch news: {response.status_code}\")\n",
    "\n",
    "columns_of_interest = ['source', 'author', 'title', 'description', 'url', 'publishedAt', 'content']\n",
    "df_articles_filtered = df_articles[columns_of_interest]\n",
    "print(df_articles_filtered.head())\n",
    "\n",
    "df_articles_filtered.to_csv(\"AAPL_NEWS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "AAPL = pd.read_csv('AAPL_Cleaned.csv')\n",
    "MSFT = pd.read_csv('MSFT_Cleaned.csv')\n",
    "GOOGL = pd.read_csv('GOOGL_Cleaned.csv')\n",
    "AMZN = pd.read_csv('AMZN_Cleaned.csv')\n",
    "META = pd.read_csv('META_Cleaned.csv')\n",
    "TSLA = pd.read_csv('TSLA_Cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAPL['label'] = (AAPL['close'] > AAPL['close'].shift(1)).astype(int)\n",
    "MSFT['label'] = (MSFT['close'] > MSFT['close'].shift(1)).astype(int)\n",
    "GOOGL['label'] = (GOOGL['close'] > GOOGL['close'].shift(1)).astype(int)\n",
    "AMZN['label'] = (AMZN['close'] > AMZN['close'].shift(1)).astype(int)\n",
    "META['label'] = (META['close'] > META['close'].shift(1)).astype(int)\n",
    "TSLA['label'] = (TSLA['close'] > TSLA['close'].shift(1)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = AAPL.drop(['timestamp', 'label'], axis=1)\n",
    "y = AAPL['label']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train and test to ensure that the model can be tuned and evaluated properly. The training set creates the model, the validation set tunes the model’s hyperparameters, and the testing set provides a final metric of how well the model is expected to perform on unseen data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection for record data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features:\n",
      "Index(['open', 'high', 'low'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\"\"\" AAPL = AAPL.drop('timestamp', axis=1)\n",
    "AAPL = AAPL.dropna() \"\"\"\n",
    "\n",
    "X = AAPL.drop('close', axis=1)\n",
    "y = AAPL['close']\n",
    "\n",
    "model = LinearRegression()\n",
    "rfe = RFE(estimator=model, n_features_to_select=3) \n",
    "selector = rfe.fit(X, y)\n",
    "\n",
    "selected_features = feature_names[selector.support_]\n",
    "print(\"Selected features:\")\n",
    "print(selected_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
